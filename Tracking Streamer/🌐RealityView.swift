import SwiftUI
import RealityKit
import ARKit
import UIKit
import Foundation

struct ğŸŒRealityView: View {
    var model: ğŸ¥½AppModel
    @StateObject private var videoModel = VideoStreamModel()
    @State private var videoPlaneEntity: ModelEntity? = nil
    @State private var isLoading: Bool = true
    @State private var gazeIndicator: ModelEntity? = nil

    var body: some View {
        RealityView { content in
            // Create a video panel anchored to the user's head, 1.0 m in front
            let headAnchor = AnchorEntity(.head)
            let planeMesh = MeshResource.generatePlane(width: 1.20, height: 0.675)
            var material = UnlitMaterial()
            material.color = .init(tint: .black)
            let panel = ModelEntity(mesh: planeMesh, materials: [material])
            panel.position = [0, -0.1, -0.83]  // ì•„ë˜ë¡œ ì´ë™ (Yì¶• -0.1)
            headAnchor.addChild(panel)
            content.add(headAnchor)
            self.videoPlaneEntity = panel
            
            // Create gaze indicator (small red dot)
            let gazeSphere = MeshResource.generateSphere(radius: 0.005)
            var gazeMaterial = UnlitMaterial()
            gazeMaterial.color = .init(tint: .red)
            let gazeIndicator = ModelEntity(mesh: gazeSphere, materials: [gazeMaterial])
            gazeIndicator.position = [0, 0, -0.83]  // íŒ¨ë„ ì•ìª½ì— ìœ„ì¹˜
            headAnchor.addChild(gazeIndicator)
            self.gazeIndicator = gazeIndicator
            
            // Create loading text texture
            if isLoading {
                let loadingText = "Loading..."
                let textImage = createTextImage(text: loadingText, size: CGSize(width: 400, height: 100))
                if let cgImage = textImage.cgImage,
                   let texture = try? TextureResource.generate(from: cgImage, options: .init(semantic: .color)) {
                    var loadingMaterial = UnlitMaterial()
                    loadingMaterial.color = .init(tint: .white, texture: .init(texture))
                    panel.model?.materials = [loadingMaterial]
                }
            }
        }
        .task { self.model.run() }
        .task { await self.model.processDeviceAnchorUpdates() }
        .task { self.model.startserver() }
        .task(priority: .low) { await self.model.processReconstructionUpdates() }
        .task {
            // Update gaze indicator position
            while true {
                await updateGazeIndicator()
                try? await Task.sleep(nanoseconds: 16_666_667) // ~60fps
            }
        }
        .task {
            // Start snapshot polling inside immersive space for mjpeg or webrtc modes
            let mode = UserDefaults.standard.string(forKey: "stream_mode") ?? "mjpeg"
            if let ip = UserDefaults.standard.string(forKey: "server_ip") {
                if mode == "mjpeg", let url = URL(string: "http://\(ip):8080/snapshot.jpg") {
                    videoModel.start(url: url, fps: 15)
                } else if mode == "webrtc", let url = URL(string: "http://\(ip):8086/snapshot.jpg") {
                    videoModel.start(url: url, fps: 15)
                }
            }
            for await img in videoModel.$image.values {
                guard let plane = self.videoPlaneEntity, let image = img, let cg = image.cgImage else { continue }
                if let tex = try? TextureResource.generate(from: cg, options: .init(semantic: .color)) {
                    var mat = UnlitMaterial()
                    mat.color = .init(tint: .white, texture: .init(tex))
                    plane.model?.materials = [mat]
                    // ì²« ë²ˆì§¸ ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ë©´ ë¡œë”© ìƒíƒœ í•´ì œ
                    if isLoading {
                        isLoading = false
                    }
                }
            }
        }
        // Removed WebRTC WKWebView overlay to avoid black covering in immersive
        // WebRTCëŠ” WKWebViewë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ immersive íŒ¨ë„ì—ì„œëŠ” MJPEGë§Œ ë Œë”ë§
    }
    
    private func updateGazeIndicator() async {
        guard let gazeIndicator = self.gazeIndicator,
              let panel = self.videoPlaneEntity else { return }
        
        let eyeData = DataManager.shared.latestEyeTrackingData
        
        // ì‹œì„ ê³¼ íŒ¨ë„ì˜ êµì  ê³„ì‚°
        let gazeOrigin = eyeData.gazeOrigin
        let gazeDirection = eyeData.gazeDirection
        
        // íŒ¨ë„ì€ Z = -0.83 í‰ë©´ì— ìœ„ì¹˜
        let panelZ: Float = -0.83
        
        // ì‹œì„ ì´ íŒ¨ë„ê³¼ êµì°¨í•˜ëŠ”ì§€ í™•ì¸
        if gazeDirection.z != 0 {
            let t = (panelZ - gazeOrigin.z) / gazeDirection.z
            
            if t > 0 { // ì‹œì„ ì´ ì•ìª½ì„ í–¥í•¨
                let intersectionX = gazeOrigin.x + t * gazeDirection.x
                let intersectionY = gazeOrigin.y + t * gazeDirection.y
                
                // íŒ¨ë„ í¬ê¸° ë‚´ì— ìˆëŠ”ì§€ í™•ì¸ (width: 1.20, height: 0.675)
                let panelWidth: Float = 0.6  // íŒ¨ë„ ë„ˆë¹„ì˜ ì ˆë°˜
                let panelHeight: Float = 0.3375  // íŒ¨ë„ ë†’ì´ì˜ ì ˆë°˜
                
                if abs(intersectionX) <= panelWidth && abs(intersectionY - (-0.1)) <= panelHeight {
                    // íŒ¨ë„ ë‚´ë¶€ì— ìˆìœ¼ë©´ ë¹¨ê°„ ì  í‘œì‹œ
                    gazeIndicator.position = [intersectionX, intersectionY, panelZ + 0.01]
                    gazeIndicator.isEnabled = true
                } else {
                    // íŒ¨ë„ ì™¸ë¶€ì— ìˆìœ¼ë©´ ìˆ¨ê¹€
                    gazeIndicator.isEnabled = false
                }
            } else {
                gazeIndicator.isEnabled = false
            }
        } else {
            gazeIndicator.isEnabled = false
        }
    }
    
    private func createTextImage(text: String, size: CGSize) -> UIImage {
        let renderer = UIGraphicsImageRenderer(size: size)
        return renderer.image { context in
            // Black background
            UIColor.black.setFill()
            context.fill(CGRect(origin: .zero, size: size))
            
            // White text
            let attributes: [NSAttributedString.Key: Any] = [
                .font: UIFont.systemFont(ofSize: 40, weight: .bold),
                .foregroundColor: UIColor.white
            ]
            
            let textSize = text.size(withAttributes: attributes)
            let textRect = CGRect(
                x: (size.width - textSize.width) / 2,
                y: (size.height - textSize.height) / 2,
                width: textSize.width,
                height: textSize.height
            )
            
            text.draw(in: textRect, withAttributes: attributes)
        }
    }
}



